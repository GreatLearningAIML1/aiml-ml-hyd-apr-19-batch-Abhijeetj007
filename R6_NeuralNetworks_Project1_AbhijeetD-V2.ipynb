{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYk8NG3yOIT9"
   },
   "source": [
    "## Deep learning - Project 1\n",
    "\n",
    "Given a Bank customer, can we build a classifier which can determine whether they will leave or not using Neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The points distribution for this case is as follows:\n",
    "\n",
    "1. Read the dataset\n",
    "\n",
    "2. Drop the columns which are unique for all users like IDs (2.5 points)\n",
    "\n",
    "3. Distinguish the feature and target set (2.5 points)\n",
    "\n",
    "4. Divide the data set into Train and test sets\n",
    "\n",
    "5. Normalize the train and test data (2.5 points)\n",
    "\n",
    "6. Initialize & build the model (10 points)\n",
    "\n",
    "7. Optimize the model (5 points)\n",
    "\n",
    "8. Predict the results using 0.5 as a threshold (5 points)\n",
    "\n",
    "9. Print the Accuracy score and confusion matrix (2.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFO6PuxzOIT_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efNjNImfOIUC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9C4aAIGOIUH",
    "outputId": "5ef9aff6-a7bd-4b26-cba6-8750955f6ca3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcoZBStrOIUQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('bank.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Drop the columns which are unique for all users like IDs (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber            int64\n",
       "CustomerId           int64\n",
       "Surname             object\n",
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(columns=['RowNumber','CustomerId','Surname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Geography = pd.Categorical(df.Geography).codes\n",
    "df.Gender = pd.Categorical(df.Gender).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>822</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>684</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619          0       0   42       2       0.00              1   \n",
       "1          608          2       0   41       1   83807.86              1   \n",
       "2          502          0       0   42       8  159660.80              3   \n",
       "3          699          0       0   39       1       0.00              2   \n",
       "4          850          2       0   43       2  125510.82              1   \n",
       "5          645          2       1   44       8  113755.78              2   \n",
       "6          822          0       1   50       7       0.00              2   \n",
       "7          376          1       0   29       4  115046.74              4   \n",
       "8          501          0       1   44       4  142051.07              2   \n",
       "9          684          0       1   27       2  134603.88              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  \n",
       "5          1               0        149756.71       1  \n",
       "6          1               1         10062.80       0  \n",
       "7          1               0        119346.88       1  \n",
       "8          0               1         74940.50       0  \n",
       "9          1               1         71725.73       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Distinguish the feature and target set (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns='Exited').astype('float32')\n",
    "y = df[\"Exited\"].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Converting into One-hot vectors using Keras\n",
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Divide the data set into Train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset in two parts\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Normalize the train and test data (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "Normalize = Normalizer()\n",
    "\n",
    "x_train = Normalize.fit_transform(x_train)\n",
    "\n",
    "x_test = Normalize.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.0712436e-03, 1.2207627e-05, 0.0000000e+00, 2.0752967e-04,\n",
       "        3.0519070e-05, 0.0000000e+00, 1.2207627e-05, 6.1038136e-06,\n",
       "        0.0000000e+00, 9.9999171e-01],\n",
       "       [4.5039640e-03, 1.0547925e-05, 1.0547925e-05, 4.4301286e-04,\n",
       "        1.0547925e-05, 7.9828304e-01, 1.0547925e-05, 1.0547925e-05,\n",
       "        1.0547925e-05, 6.0226542e-01]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Initialize & build the model (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1007 12:22:55.813936   412 deprecation.py:506] From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#Initialize Sequential model\n",
    "model_1 = tf.keras.models.Sequential()\n",
    "\n",
    "#Adding 1st dence layer\n",
    "model_1.add(tf.keras.layers.Dense(20, activation='sigmoid',input_shape=(10,)))\n",
    "\n",
    "#Add 2nd hidden layer\n",
    "model_1.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
    "\n",
    "#Adding OUTPUT layer\n",
    "model_1.add(tf.keras.layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid function is used for the two-class logistic regression, whereas the softmax function is used for the multiclass logistic regression (a.k.a. MaxEnt, multinomial logistic regression, softmax Regression, Maximum Entropy Classifier). with β=−(β0−β1)\n",
    "\n",
    "Softmax function calculates the probabilities distribution of the event over 'n' different events. In general way of saying, this function will calculate the probabilities of each target class over all possible target classes.  The purpose of the softmax classification layer is simply to transform all the net activations in your final output layer to a series of values that can be interpreted as probabilities. To do this, the softmax function is applied onto the net outputs (without an activation function or bias)\n",
    "\n",
    "we use softmax activation instead of sigmoid with the cross-entropy loss because softmax activation distributes the probability throughout each output node. But, since it is a binary classification, using sigmoid is same as softmax. For multi-class classification use sofmax with cross-entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Optimize the model (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create optimizer with non-default learning rate\n",
    "sgd_optimizer1 = tf.keras.optimizers.SGD(lr=0.3)\n",
    "\n",
    "#Compile the model\n",
    "model_1.compile(optimizer=sgd_optimizer1, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent(SGD)\n",
    "In Keras, we can do this to have SGD + Nesterov enabled, it works well for shallow networks. keras. optimizers. SGD(lr=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 3s 385us/sample - loss: 0.5086 - acc: 0.7960\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.5074 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 0.5058 - acc: 0.7960\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.5057 - acc: 0.7960\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.5041 - acc: 0.7960\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 89us/sample - loss: 0.5038 - acc: 0.7960\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.5032 - acc: 0.7960\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.5038 - acc: 0.7960\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.5029 - acc: 0.7960\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.5029 - acc: 0.7960\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.5029 - acc: 0.7960\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.5019 - acc: 0.7960\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.5021 - acc: 0.7960\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.5019 - acc: 0.7960\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.5015 - acc: 0.7960\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.5019 - acc: 0.7960\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.5010 - acc: 0.7960\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.5011 - acc: 0.7960\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.5013 - acc: 0.7960\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.5012 - acc: 0.7960\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.5004 - acc: 0.7960\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.5016 - acc: 0.7960\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.5009 - acc: 0.7960\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.5007 - acc: 0.7960\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.5006 - acc: 0.7960\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.5002 - acc: 0.7960\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.5006 - acc: 0.7960\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.5006 - acc: 0.7960\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.5006 - acc: 0.7960\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.5011 - acc: 0.7960\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.5006 - acc: 0.7960\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.5005 - acc: 0.7960\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.5004 - acc: 0.7960\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.5007 - acc: 0.7960\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.5002 - acc: 0.7960\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.5006 - acc: 0.7960\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.5004 - acc: 0.7960\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.4996 - acc: 0.7960\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.5001 - acc: 0.7960\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.5001 - acc: 0.7960\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.5000 - acc: 0.7960\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.5002 - acc: 0.7960\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.5001 - acc: 0.7960\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.5004 - acc: 0.7960\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.5002 - acc: 0.7960\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.4999 - acc: 0.7960\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.5004 - acc: 0.7960\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.4994 - acc: 0.7960\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.4997 - acc: 0.7960\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.5000 - acc: 0.7960\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.5000 - acc: 0.7960\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.4996 - acc: 0.7960\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.4994 - acc: 0.7960\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4997 - acc: 0.7960\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.4998 - acc: 0.7960\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.5004 - acc: 0.7960\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.4998 - acc: 0.7960\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.4997 - acc: 0.7960\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.4995 - acc: 0.7960\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.4998 - acc: 0.7960\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.4999 - acc: 0.7960\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.4999 - acc: 0.7960\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.4993 - acc: 0.7960\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.4992 - acc: 0.7960\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.5002 - acc: 0.7960\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.4998 - acc: 0.7960\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.5001 - acc: 0.7960\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.4998 - acc: 0.7960\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.4995 - acc: 0.7960\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.4996 - acc: 0.7960\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.4997 - acc: 0.7960\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.4995 - acc: 0.7960\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.4996 - acc: 0.7960\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.4994 - acc: 0.7960\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.4999 - acc: 0.7960\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.4997 - acc: 0.7960\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.4996 - acc: 0.7960\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.4995 - acc: 0.7960\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.4997 - acc: 0.7960\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.4998 - acc: 0.7960\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.4994 - acc: 0.7960\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4997 - acc: 0.7960\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.4992 - acc: 0.7960\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4997 - acc: 0.7960\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4995 - acc: 0.7960\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4994 - acc: 0.7960\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.4995 - acc: 0.7960\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4994 - acc: 0.7960\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4995 - acc: 0.7960\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4994 - acc: 0.7960\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4996 - acc: 0.7960\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4996 - acc: 0.7960\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4993 - acc: 0.7960\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4992 - acc: 0.7960\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.4995 - acc: 0.7960\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4994 - acc: 0.7960\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4996 - acc: 0.7960\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4996 - acc: 0.7960\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.4996 - acc: 0.7960\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.4994 - acc: 0.7960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xc72e12bbe0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Predict the results using 0.5 as a threshold (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = model_1.predict(x_test)\n",
    "y_test_predict = y_test_predict.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max function gives the largest possible value of f(x) for any x in the domain, which is the function value achieved by any element of the argmax. Unlike the argmax, the max function is unique since all elements of the argmax achieve the same value. However, the max may not exist because the argmax may be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = (model_1.predict_proba(x_test)[:,1] >= 0.5).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Print the Accuracy score and confusion matrix (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy percentage is : 79.75\n"
     ]
    }
   ],
   "source": [
    "print(\"The test accuracy percentage is :\", accuracy*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1595,    0],\n",
       "       [ 405,    0]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach2 by using Rectified Liner Activation Function for First Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The rectified linear activation function is a piecewise linear function that will output the input directly if is positive, otherwise, it will output zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('bank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data.drop(columns=['RowNumber','CustomerId','Surname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df1.drop(columns='Exited')\n",
    "y1 = df1[\"Exited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure   Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2      0.00              1   \n",
       "1          608     Spain  Female   41       1  83807.86              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X_1 = LabelEncoder()\n",
    "x1['Geography'] = labelencoder_X_1.fit_transform(x1['Geography'])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "x1['Gender'] = labelencoder_X_1.fit_transform(x1['Gender'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features=[1])\n",
    "x1 = onehotencoder.fit_transform(x1).toarray()\n",
    "x1 = x1[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x1_train = sc.fit_transform(x1_train)\n",
    "x1_test = sc.transform(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1007 12:24:20.554428   412 deprecation_wrapper.py:119] From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initializing the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "W1007 12:24:21.596860   412 deprecation_wrapper.py:119] From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1007 12:24:21.769140   412 deprecation_wrapper.py:119] From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Adding the input Layer and the first Hidden layer using the Rectifier Activation \n",
    "classifier.add(Dense(output_dim=6, init='uniform', activation='relu', input_dim=11))\n",
    "\n",
    "# Adding the input Layer and the second Hidden layer using the Rectifier Activation \n",
    "classifier.add(Dense(output_dim=6, init='uniform', activation='relu'))\n",
    "\n",
    "# Adding the output layer using Sigmoid\n",
    "classifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU stands for rectified linear unit, and is a type of activation function. Mathematically, it is defined as y = max(0, x). Visually, it looks like the following: ReLUs are the most commonly used activation function in neural networks, especially in CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1007 12:24:22.634735   412 deprecation_wrapper.py:119] From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1007 12:24:22.747808   412 deprecation_wrapper.py:119] From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1007 12:24:22.795848   412 deprecation.py:323] From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1007 12:24:24.667738   412 deprecation_wrapper.py:119] From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 7s 821us/step - loss: 0.4808 - acc: 0.7959\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 2s 299us/step - loss: 0.4261 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 2s 281us/step - loss: 0.4209 - acc: 0.8039\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 2s 269us/step - loss: 0.4173 - acc: 0.8249\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 2s 269us/step - loss: 0.4155 - acc: 0.8285\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 2s 249us/step - loss: 0.4138 - acc: 0.8317\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 2s 252us/step - loss: 0.4125 - acc: 0.8329\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 2s 247us/step - loss: 0.4118 - acc: 0.8322\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 2s 249us/step - loss: 0.4105 - acc: 0.8315\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 2s 247us/step - loss: 0.4095 - acc: 0.8339\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 2s 246us/step - loss: 0.4090 - acc: 0.8329\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 2s 249us/step - loss: 0.4082 - acc: 0.8332\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 2s 248us/step - loss: 0.4074 - acc: 0.8336\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 2s 254us/step - loss: 0.4069 - acc: 0.8344\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.4062 - acc: 0.8355\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 2s 236us/step - loss: 0.4058 - acc: 0.8331\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.4055 - acc: 0.8332\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 2s 243us/step - loss: 0.4050 - acc: 0.8351\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 2s 233us/step - loss: 0.4051 - acc: 0.8331\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 2s 245us/step - loss: 0.4046 - acc: 0.8344\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.4041 - acc: 0.8360\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.4041 - acc: 0.8359\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.4041 - acc: 0.8347\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 2s 211us/step - loss: 0.4038 - acc: 0.8354\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 0.4022 - acc: 0.8364\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 2s 238us/step - loss: 0.4037 - acc: 0.8334\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.4026 - acc: 0.8347\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.4029 - acc: 0.8352\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 2s 211us/step - loss: 0.4032 - acc: 0.8346\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 0.4029 - acc: 0.8352\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 2s 211us/step - loss: 0.4026 - acc: 0.8350\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 2s 214us/step - loss: 0.4031 - acc: 0.8337\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 2s 215us/step - loss: 0.4030 - acc: 0.8344\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 2s 211us/step - loss: 0.4024 - acc: 0.8329\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 2s 214us/step - loss: 0.4024 - acc: 0.8355\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 2s 214us/step - loss: 0.4024 - acc: 0.8339\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.4020 - acc: 0.8352\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.4018 - acc: 0.8349\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.4022 - acc: 0.8335\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 2s 203us/step - loss: 0.4018 - acc: 0.8364\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 0.4020 - acc: 0.8362\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 2s 236us/step - loss: 0.4022 - acc: 0.8351\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 2s 231us/step - loss: 0.4023 - acc: 0.8352\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 2s 227us/step - loss: 0.4016 - acc: 0.8346\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.4019 - acc: 0.8351\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 2s 252us/step - loss: 0.4016 - acc: 0.8355\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.4011 - acc: 0.8354\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 2s 238us/step - loss: 0.4019 - acc: 0.8340\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 2s 204us/step - loss: 0.4012 - acc: 0.8357\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 2s 288us/step - loss: 0.4015 - acc: 0.8357\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 2s 297us/step - loss: 0.4019 - acc: 0.8347\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.4019 - acc: 0.8351\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 2s 215us/step - loss: 0.4012 - acc: 0.8359\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.4016 - acc: 0.8335\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.4017 - acc: 0.8347\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.4015 - acc: 0.8342\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 0.4010 - acc: 0.8355\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 2s 201us/step - loss: 0.4014 - acc: 0.8356\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 0.4015 - acc: 0.8349\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.4016 - acc: 0.8350\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 2s 241us/step - loss: 0.4014 - acc: 0.8346\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 2s 224us/step - loss: 0.4011 - acc: 0.8362\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 2s 213us/step - loss: 0.4009 - acc: 0.8372\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.4011 - acc: 0.8357\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 0.4013 - acc: 0.8357\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 0.4010 - acc: 0.8345\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 2s 208us/step - loss: 0.4012 - acc: 0.8349\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 0.4016 - acc: 0.8367\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 0.4009 - acc: 0.8352\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.4010 - acc: 0.8364\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 2s 211us/step - loss: 0.4014 - acc: 0.8352\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 2s 213us/step - loss: 0.4010 - acc: 0.8352\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 0.4010 - acc: 0.8354\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.4005 - acc: 0.8350\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 2s 208us/step - loss: 0.4013 - acc: 0.8345\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.4007 - acc: 0.8341\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 2s 207us/step - loss: 0.4007 - acc: 0.8351\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 2s 208us/step - loss: 0.4014 - acc: 0.8350\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 2s 213us/step - loss: 0.4006 - acc: 0.8356\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 2s 216us/step - loss: 0.4014 - acc: 0.8356\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.4007 - acc: 0.8360\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 2s 207us/step - loss: 0.4013 - acc: 0.8340\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 2s 207us/step - loss: 0.4011 - acc: 0.8350\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 2s 247us/step - loss: 0.4010 - acc: 0.8334\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 2s 242us/step - loss: 0.4009 - acc: 0.8349\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 2s 236us/step - loss: 0.4000 - acc: 0.8352\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.4007 - acc: 0.8357\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.4011 - acc: 0.8354\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 2s 232us/step - loss: 0.4006 - acc: 0.8359\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 2s 213us/step - loss: 0.4004 - acc: 0.8344\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 2s 206us/step - loss: 0.4009 - acc: 0.8356\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 2s 206us/step - loss: 0.4011 - acc: 0.8360\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 2s 200us/step - loss: 0.4011 - acc: 0.8352\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 2s 213us/step - loss: 0.4009 - acc: 0.8341\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 2s 203us/step - loss: 0.4007 - acc: 0.8344\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 2s 205us/step - loss: 0.4011 - acc: 0.8359\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.4008 - acc: 0.8346\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 2s 205us/step - loss: 0.4006 - acc: 0.8349\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 2s 207us/step - loss: 0.4010 - acc: 0.8356\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 2s 204us/step - loss: 0.4006 - acc: 0.8355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xc72f768f98>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to training set\n",
    "classifier.fit(x1_train, y1_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It has been observed that as the number of epoch increases accuracy is almost same and losses decreses upto certain level he it is almost same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediciting the test results \n",
    "y1_pred = classifier.predict(x1_test)\n",
    "y1_pred = (y1_pred > 0.5)\n",
    "y1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1530,   65],\n",
       "       [ 246,  159]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "confusion_matrix(y1_test, y1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.867"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The confusion Matrix shows the accurac of 87%\n",
    "(1557+177)/2000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of both approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Approach1 has given the accuray of 79%. The activation function for Hidden layer was Sigmoid and output layer was sofmax\n",
    "\n",
    "The Approach2 has given the accuracy of 87%. The activation function for Hidden layer was Rectifier and output layer was Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The sigmoid function is used for the two-class logistic regression, so in approach two we have used sigmoid which is giving output in two class (Customer will leave or not).whereas in approach one we have used the softmax function is used for the multiclass logistic regression (a.k.a. MaxEnt, multinomial logistic regression, softmax Regression, Maximum Entropy Classifier). with β=−(β0−β1)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Classification_F-MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
